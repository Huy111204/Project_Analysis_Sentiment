import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import joblib
import time
import os

# Load model/tokenizer/encoder
MODEL_PATH = r"C:\Users\Lenovo\OneDrive - ueh.edu.vn\Documents\doan\cuoi_ky\app\phobert_model"
TOKENIZER_PATH = r"C:\Users\Lenovo\OneDrive - ueh.edu.vn\Documents\doan\cuoi_ky\app\phobert_tokenizer"
ENCODER_PATH = r"C:\Users\Lenovo\OneDrive - ueh.edu.vn\Documents\doan\cuoi_ky\app\label_encoder.pkl"
FEEDBACK_PATH = r"C:\Users\Lenovo\OneDrive - ueh.edu.vn\Documents\doan\cuoi_ky\app\feedback.csv"


model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to("cuda" if torch.cuda.is_available() else "cpu")
tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)
encoder = joblib.load(ENCODER_PATH)

# Predict comment
def predict(text):
    model.eval()
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=64).to(model.device)
    with torch.no_grad():
        outputs = model(**inputs)
        pred = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]
    return encoder.inverse_transform([pred])[0]

# App UI
st.set_page_config(page_title="Vietnamese Sentiment Analysis", layout="wide")
st.title("üìä Sentiment Prediction App with PhoBERT")
st.markdown("Upload file CSV ch·ª©a c·ªôt `comment` ƒë·ªÉ d·ª± ƒëo√°n c·∫£m x√∫c (POS/NEU/NEG), tr·ª±c quan v√† g·ª≠i ph·∫£n h·ªìi n·∫øu c·∫ßn.")

uploaded_file = st.file_uploader("üìÅ Ch·ªçn file CSV", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    if "comment" not in df.columns:
        st.error("‚ö†Ô∏è File kh√¥ng c√≥ c·ªôt 'comment'")
    else:
        df = df.dropna(subset=['comment']).copy()
        df['prediction'] = df['comment'].apply(predict)

        st.success("‚úÖ ƒê√£ ph√¢n lo·∫°i xong")
        st.dataframe(df.head())

        # ==== Visualization Layout ====
        st.subheader("üìà Ph√¢n ph·ªëi c·∫£m x√∫c")

        col1, col2 = st.columns(2)

        with col1:
            fig, ax = plt.subplots(figsize=(5, 3))
            sns.countplot(x='prediction', data=df, ax=ax, palette='pastel')
            ax.set_title("Bar Chart")
            st.pyplot(fig)

        with col2:
            fig2, ax2 = plt.subplots(figsize=(5, 3))
            df['prediction'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax2, colors=sns.color_palette('pastel'))
            ax2.set_ylabel("")
            ax2.set_title("Pie Chart")
            st.pyplot(fig2)

        st.subheader("‚òÅÔ∏è WordCloud theo nh√£n")

        labels = df['prediction'].unique()
        cols = st.columns(2)

        for idx, label in enumerate(labels):
            text = " ".join(df[df['prediction'] == label]['comment'].astype(str))
            wordcloud = WordCloud(width=600, height=300, background_color="white").generate(text)
            with cols[idx % 2]:
                st.markdown(f"**{label}**")
                fig_wc, ax_wc = plt.subplots(figsize=(6, 3))
                ax_wc.imshow(wordcloud, interpolation='bilinear')
                ax_wc.axis('off')
                st.pyplot(fig_wc)

        # Download
        st.subheader("üì• T·∫£i k·∫øt qu·∫£")
        st.download_button("üíæ T·∫£i file k·∫øt qu·∫£", df.to_csv(index=False).encode('utf-8'), file_name="prediction_results.csv")

        # Feedback UI
        st.subheader("‚úèÔ∏è G√≥p √Ω nh√£n d·ª± ƒëo√°n")
        for idx, row in df.iterrows():
            with st.expander(f"üìå D√≤ng {idx}: {row['comment'][:60]}..."):
                st.write(f"**D·ª± ƒëo√°n:** {row['prediction']}")
                correct = st.selectbox("Ch·ªçn nh√£n ƒë√∫ng:", encoder.classes_, key=f"select_{idx}")
                if st.button("üì© G·ª≠i ph·∫£n h·ªìi", key=f"send_{idx}"):
                    fb = pd.DataFrame([{
                        "index": idx,
                        "comment": row['comment'],
                        "model_prediction": row['prediction'],
                        "correct_label": correct,
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    }])
                    if os.path.exists(FEEDBACK_PATH):
                        fb.to_csv(FEEDBACK_PATH, mode="a", index=False, header=False)
                    else:
                        fb.to_csv(FEEDBACK_PATH, index=False)
                    st.success("‚úÖ Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c ghi nh·∫≠n")
