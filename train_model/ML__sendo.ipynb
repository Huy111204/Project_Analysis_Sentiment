{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Kết nối với gg drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VGtskbF9FE_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6s_HOqWdNs6"
      },
      "outputs": [],
      "source": [
        "# Đọc file CSV\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cuoi_ky/train_model/Data/data - data.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cài đặt thư viện và kiểm tra dữ liệu\n",
        "!pip install underthesea emoji\n",
        "df.info()\n",
        "print(df.isnull().sum())\n",
        "df[\"label\"].unique()"
      ],
      "metadata": {
        "id": "9zEmI91CFwf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loại bỏ cột thừa\n",
        "df = df.drop(columns=['Unnamed: 3', 'rate'], errors='ignore')"
      ],
      "metadata": {
        "id": "5LWZsXVUIUOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from underthesea import word_tokenize\n",
        "import re, emoji\n",
        "\n",
        "# Load stopwords\n",
        "stop_words_df = pd.read_csv('/content/drive/MyDrive/cuoi_ky/train_model/Data/vietnamese-stopwords-dash.txt', header=None)\n",
        "stop_words = set(stop_words_df[0].values)\n",
        "\n",
        "# Hàm xử lý câu\n",
        "def process_sentences(sentence):\n",
        "    sentence = str(sentence).lower()\n",
        "    sentence = re.sub(r'\\d[\\d\\.,]*\\d', '<NUMBER>', sentence)\n",
        "    sentence = re.sub(r'(https?://\\S+|www\\.\\S+)', '<URL>', sentence)\n",
        "    sentence = re.sub(r'@\\w+', '<USER>', sentence)\n",
        "    sentence = re.sub(r'#\\w+', '<HASHTAG>', sentence)\n",
        "    sentence = emoji.replace_emoji(sentence, replace=\"<EMOJI>\")\n",
        "    sentence = re.sub(r'[^\\wÀ-ỹ0-9<>\\?\\!\\.,;:\\- ]+', ' ', sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "    tokens = word_tokenize(sentence)\n",
        "    tokens = [w for w in tokens if w not in stop_words and len(w)>1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Áp dụng tiền xử lý\n",
        "df['comment'] = df['comment'].apply(process_sentences)\n",
        "\n",
        "# Loại bỏ duplicates và lọc comment ngắn\n",
        "df = df[~df['comment'].str.fullmatch(r'\\d*')]\n",
        "df = df.drop_duplicates(subset='comment').reset_index(drop=True)\n",
        "\n",
        "df['label'].value_counts()\n",
        "df"
      ],
      "metadata": {
        "id": "rtZ2dH8p6lYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Re-tokenize comments if needed\n",
        "def tokenize(text):\n",
        "    return re.findall(r'\\w+', str(text).lower())\n",
        "\n",
        "df = df.dropna(subset=['comment', 'label'])\n",
        "df['tokens'] = df['comment'].apply(tokenize)\n",
        "# Top 20 most frequent words across entire dataset\n",
        "all_tokens = [token for tokens in df['tokens'] for token in tokens]\n",
        "top_tokens = Counter(all_tokens).most_common(20)\n",
        "words, counts = zip(*top_tokens)\n",
        "\n",
        "# Bar chart Top 20 words\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(counts), y=list(words), palette='viridis')\n",
        "plt.title('Top 20 Most Common Words (All Labels)')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Word')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='label', data=df, palette='Set2')\n",
        "plt.title('Distribution of Sentiment Labels')\n",
        "plt.xlabel('Sentiment Label')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# WordCloud for each sentiment\n",
        "for label in df['label'].unique():\n",
        "    label_text = ' '.join(df[df['label'] == label]['comment'])\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(label_text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(f'Word Cloud for {label} Sentiment')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "s6yCGFNg83tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression , SVM , Naive Bayes\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "ivUTjdU8pFvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cấu hình TF-IDF nâng cao\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
        "\n",
        "# Train/Test split\n",
        "X = df[\"comment\"]\n",
        "y = df[\"label\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Mô hình cập nhật\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
        "    \"Linear SVM\": LinearSVC(class_weight=\"balanced\"),\n",
        "    \"Naive Bayes\": MultinomialNB()\n",
        "}\n",
        "\n",
        "# Đánh giá mô hình\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n====== {name} ======\")\n",
        "    pipeline = Pipeline([(\"tfidf\", tfidf), (\"clf\", model)])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"report\": report\n",
        "    }\n",
        "\n",
        "    print(\"Accuracy:\", round(acc, 4))\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=[\"NEG\", \"NEU\", \"POS\"])\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"NEG\", \"NEU\", \"POS\"],\n",
        "                yticklabels=[\"NEG\", \"NEU\", \"POS\"])\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iRruUFxNAnkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tạo bảng kết quả từ dict 'results'\n",
        "score_df = pd.DataFrame({\n",
        "    model: {\n",
        "        \"accuracy\": round(metrics[\"accuracy\"], 4),\n",
        "        \"precision\": round(metrics[\"report\"][\"weighted avg\"][\"precision\"], 4),\n",
        "        \"recall\": round(metrics[\"report\"][\"weighted avg\"][\"recall\"], 4),\n",
        "        \"f1\": round(metrics[\"report\"][\"weighted avg\"][\"f1-score\"], 4)\n",
        "    }\n",
        "    for model, metrics in results.items()\n",
        "}).T\n",
        "\n",
        "# In bảng tổng hợp\n",
        "print(\"\\n Tổng hợp kết quả mô hình:\\n\")\n",
        "print(score_df)\n",
        "\n",
        "# Vẽ biểu đồ Precision, Recall, F1\n",
        "score_df[[\"precision\", \"recall\", \"f1\"]].plot(\n",
        "    kind=\"bar\",\n",
        "    figsize=(10, 6),\n",
        "    color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"],\n",
        "    edgecolor='black'\n",
        ")\n",
        "plt.title(\"So sánh mô hình: Precision - Recall - F1\", fontsize=14)\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JBjHr7Uv6QWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}