{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install joblib underthesea emoji torch scikit-learn tqdm"
      ],
      "metadata": {
        "id": "A9JPfL5T1zFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y transformers accelerate peft\n",
        "!pip install transformers==4.36.2 accelerate==0.23.0 peft==0.7.1\n"
      ],
      "metadata": {
        "id": "UFwARH1eXAy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byQMHX-z1rIu"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from underthesea import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback\n",
        ")\n",
        "import torch\n",
        "def load_and_preprocess_data(file_path, stop_words_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "    df = df.dropna(subset=['comment', 'label'])\n",
        "    stop_words = set(pd.read_csv(stop_words_path, header=None)[0].tolist())\n",
        "\n",
        "    def process_sentence(sentence):\n",
        "        s = str(sentence).lower()\n",
        "        s = re.sub(r'\\d[\\d\\.,]*\\d', '<NUMBER>', s)\n",
        "        s = re.sub(r'(https?://\\S+|www\\.\\S+)', '<URL>', s)\n",
        "        s = re.sub(r'@\\w+', '<USER>', s)\n",
        "        s = re.sub(r'#\\w+', '<HASHTAG>', s)\n",
        "        s = emoji.replace_emoji(s, replace=\"<EMOJI>\")\n",
        "        s = re.sub(r'[^\\wÀ-ỹ0-9<>\\?\\!\\.,;:\\- ]+', ' ', s)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        tokens = word_tokenize(s)\n",
        "        tokens = [w for w in tokens if w not in stop_words and len(w)>1]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    tqdm.pandas(desc=\"Preprocessing\")\n",
        "    df['comment'] = df['comment'].progress_apply(process_sentence)\n",
        "    train_df, test_df = train_test_split(\n",
        "        df[['comment','label']], test_size=0.2,\n",
        "        stratify=df['label'], random_state=42\n",
        "    )\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = load_and_preprocess_data(\n",
        "    \"/content/drive/MyDrive/cuoi_ky/train_model/Data/data - data.csv\",\n",
        "    \"/content/drive/MyDrive/cuoi_ky/train_model/Data/vietnamese-stopwords-dash.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "JJAwNRBJa8yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "bK9di2kv7_SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "train_labels = encoder.fit_transform(train_df['label'])\n",
        "test_labels = encoder.transform(test_df['label'])\n",
        "joblib.dump(encoder, '/content/drive/MyDrive/cuoi_ky/train_model/Model/label_encoder.pkl')\n",
        "\n",
        "# Tokenize\n",
        "model_name = \"wonrax/phobert-base-vietnamese-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(\n",
        "    train_df['comment'].tolist(), truncation=True,\n",
        "    padding=True, max_length=64\n",
        ")\n",
        "test_encodings = tokenizer(\n",
        "    test_df['comment'].tolist(), truncation=True,\n",
        "    padding=True, max_length=64\n",
        ")\n",
        "# Prepare dataset for Trainer\n",
        "torch.manual_seed(42)\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=len(encoder.classes_)\n",
        ")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "cWDV4bf2dQ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TrainingArguments using epoch-based eval/save + early stopping\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/cuoi_ky/train_model/Model',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    greater_is_better=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    fp16=True\n",
        ")\n",
        "# Compute metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
      ],
      "metadata": {
        "id": "_hAsKJfotBYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer with EarlyStoppingCallback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ],
      "metadata": {
        "id": "vRdf_KNbtNgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & evaluate\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "EoQc2Imt1WIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu mô hình và tokenizer\n",
        "model.save_pretrained(\"/content/drive/MyDrive/cuoi_ky/train_model/Model/phobert_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/cuoi_ky/train_model/Model/phobert_tokenizer\")\n"
      ],
      "metadata": {
        "id": "0lTHY35GAVlM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}